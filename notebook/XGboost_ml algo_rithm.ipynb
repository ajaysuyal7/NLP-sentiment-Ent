{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcFewiw9x5TrPv1tSNgytI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"e1I0VsifOxcY","executionInfo":{"status":"ok","timestamp":1770274202437,"user_tz":-330,"elapsed":35637,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"34270e49-d4be-45a2-909a-79dd5d784865"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mlflow\n","  Downloading mlflow-3.9.0-py3-none-any.whl.metadata (31 kB)\n","Collecting boto3\n","  Downloading boto3-1.42.42-py3-none-any.whl.metadata (6.8 kB)\n","Collecting awscli\n","  Downloading awscli-1.44.32-py3-none-any.whl.metadata (11 kB)\n","Collecting optuna\n","  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.3)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.1)\n","Collecting mlflow-skinny==3.9.0 (from mlflow)\n","  Downloading mlflow_skinny-3.9.0-py3-none-any.whl.metadata (32 kB)\n","Collecting mlflow-tracing==3.9.0 (from mlflow)\n","  Downloading mlflow_tracing-3.9.0-py3-none-any.whl.metadata (19 kB)\n","Collecting Flask-CORS<7 (from mlflow)\n","  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n","Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.18.2)\n","Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n","Collecting docker<8,>=4.0.0 (from mlflow)\n","  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting graphene<4 (from mlflow)\n","  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n","Collecting gunicorn<24 (from mlflow)\n","  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n","Collecting huey<3,>=2.5.4 (from mlflow)\n","  Downloading huey-2.6.0-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n","Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n","Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n","Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n","Collecting skops<1 (from mlflow)\n","  Downloading skops-0.13.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.46)\n","Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (6.2.6)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.3.1)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.2)\n","Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.9.0->mlflow)\n","  Downloading databricks_sdk-0.84.0-py3-none-any.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.123.10)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.46)\n","Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.7.1)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\n","Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.37.0)\n","Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (25.0)\n","Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (5.29.5)\n","Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.12.3)\n","Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.2.1)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (6.0.3)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.32.4)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.5.5)\n","Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (4.15.0)\n","Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.40.0)\n","Collecting botocore<1.43.0,>=1.42.42 (from boto3)\n","  Downloading botocore-1.42.42-py3-none-any.whl.metadata (5.9 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n","  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.17.0,>=0.16.0 (from boto3)\n","  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n","Collecting docutils<=0.19,>=0.18.1 (from awscli)\n","  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n","Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Collecting rsa<4.8,>=3.1.2 (from awscli)\n","  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.42->boto3) (2.9.0.post0)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.42->boto3) (2.5.0)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.2)\n","Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (0.1.5)\n","Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.5)\n","Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n","Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n","  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.3.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.3)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.2)\n","Requirement already satisfied: prettytable>=3.9 in /usr/local/lib/python3.12/dist-packages (from skops<1->mlflow) (3.17.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (3.0)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (2.47.0)\n","Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.50.0)\n","Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.0.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (4.0.12)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow) (3.23.0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow) (0.58b0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable>=3.9->skops<1->mlflow) (0.5.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.42->boto3) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (2026.1.4)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.9.0->mlflow) (0.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (5.0.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.9.0->mlflow) (4.12.1)\n","Downloading mlflow-3.9.0-py3-none-any.whl (9.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_skinny-3.9.0-py3-none-any.whl (2.8 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlflow_tracing-3.9.0-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.42.42-py3-none-any.whl (140 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading awscli-1.44.32-py3-none-any.whl (4.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading botocore-1.42.42-py3-none-any.whl (14.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading optuna-4.7.0-py3-none-any.whl (413 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docutils-0.19-py3-none-any.whl (570 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n","Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huey-2.6.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n","Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading skops-0.13.0-py3-none-any.whl (131 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n","Downloading databricks_sdk-0.84.0-py3-none-any.whl (796 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n","Installing collected packages: huey, rsa, jmespath, gunicorn, graphql-core, docutils, colorlog, colorama, graphql-relay, docker, botocore, skops, s3transfer, optuna, graphene, Flask-CORS, databricks-sdk, boto3, awscli, mlflow-tracing, mlflow-skinny, mlflow\n","  Attempting uninstall: rsa\n","    Found existing installation: rsa 4.9.1\n","    Uninstalling rsa-4.9.1:\n","      Successfully uninstalled rsa-4.9.1\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.21.2\n","    Uninstalling docutils-0.21.2:\n","      Successfully uninstalled docutils-0.21.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sphinx 8.2.3 requires docutils<0.22,>=0.20, but you have docutils 0.19 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Flask-CORS-6.0.2 awscli-1.44.32 boto3-1.42.42 botocore-1.42.42 colorama-0.4.6 colorlog-6.10.1 databricks-sdk-0.84.0 docker-7.1.0 docutils-0.19 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.6.0 jmespath-1.1.0 mlflow-3.9.0 mlflow-skinny-3.9.0 mlflow-tracing-3.9.0 optuna-4.7.0 rsa-4.7.2 s3transfer-0.16.0 skops-0.13.0\n"]}],"source":["!pip install mlflow boto3 awscli optuna xgboost imbalanced-learn"]},{"cell_type":"code","source":["import mlflow\n","# Step 2: Set up the MLflow tracking server\n","mlflow.set_tracking_uri(\"http://ec2-98-91-228-79.compute-1.amazonaws.com:5000/\")"],"metadata":{"id":"QyaBLHJOSmK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!aws configure"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mo9Qh04YSxT5","executionInfo":{"status":"ok","timestamp":1770274230553,"user_tz":-330,"elapsed":23668,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"b9b44f32-1188-4483-fd51-c5691654f94e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AWS Access Key ID [None]: AKIA2ONSQN5Y76DX5WGZ\n","AWS Secret Access Key [None]: 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\n","Default region name [None]: us-east-1\n","Default output format [None]: \n"]}]},{"cell_type":"code","source":["# Set or create an experiment\n","mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ad3B5jYS8x9","executionInfo":{"status":"ok","timestamp":1770274240752,"user_tz":-330,"elapsed":179,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"b19e2219-90c8-4b0e-cc64-96b1f3c1ce09"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Experiment: artifact_location='s3://mlflow-redit-user/5', creation_time=1770034855441, experiment_id='5', last_update_time=1770034855441, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={'mlflow.experimentKind': 'custom_model_development'}>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import optuna\n","import mlflow\n","import mlflow.sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, log_loss, f1_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.over_sampling import SMOTE\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd"],"metadata":{"id":"8mAaz40pTHwJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/reddit_preprocessing.csv').dropna()\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKIP-dQPTVjw","executionInfo":{"status":"ok","timestamp":1770274283381,"user_tz":-330,"elapsed":150,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"738923d4-2b0c-4561-e57b-bce8e9e0152a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(36662, 2)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# # Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n","# df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n","\n","# # Step 2: Remove rows where the target labels (category) are NaN\n","# df = df.dropna(subset=['category'])\n","\n","# ngram_range = (1, 3)  # Trigram setting\n","# max_features = 1000  # Set max_features to 1000 for TF-IDF\n","\n","# # Step 4: Train-test split before vectorization and resampling\n","# X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n","\n","# # Step 2: Vectorization using TF-IDF, fit on training data only\n","# vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n","# X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n","# X_test_vec = vectorizer.transform(X_test)  # Transform test data\n","\n","# smote = SMOTE(random_state=42)\n","# X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n","\n","# # Function to log results in MLflow\n","# def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n","#     with mlflow.start_run():\n","#         # Log model type\n","#         mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n","#         mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n","\n","#         # Log algorithm name as a parameter\n","#         mlflow.log_param(\"algo_name\", model_name)\n","\n","#         # Train model\n","#         model.fit(X_train, y_train)\n","#         y_pred = model.predict(X_test)\n","\n","#         # Log accuracy\n","#         accuracy = accuracy_score(y_test, y_pred)\n","#         mlflow.log_metric(\"accuracy\", accuracy)\n","\n","#         # Log classification report\n","#         classification_rep = classification_report(y_test, y_pred, output_dict=True)\n","#         for label, metrics in classification_rep.items():\n","#             if isinstance(metrics, dict):\n","#                 for metric, value in metrics.items():\n","#                     mlflow.log_metric(f\"{label}_{metric}\", value)\n","\n","#         # Log the model\n","#         mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n","\n","\n","# # Step 6: Optuna objective function for XGBoost\n","# def objective_xgboost(trial):\n","#     n_estimators = trial.suggest_int('n_estimators', 50, 300)\n","#     learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n","#     max_depth = trial.suggest_int('max_depth', 3, 10)\n","\n","#     model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42,n_jobs=-1)\n","#     return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n","\n","\n","# # Step 7: Run Optuna for XGBoost, log the best model only\n","# def run_optuna_experiment():\n","#     study = optuna.create_study(direction=\"maximize\")\n","#     study.optimize(objective_xgboost, n_trials=30)\n","\n","#     # Get the best parameters and log only the best model\n","#     best_params = study.best_params\n","#     best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n","\n","#     # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n","#     log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n","\n","# # Run the experiment for XGBoost\n","# run_optuna_experiment()"],"metadata":{"id":"a6i4d0IXTYL7","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n","df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n","\n","# Step 2: Remove rows where the target labels (category) are NaN\n","df = df.dropna(subset=['category'])\n","\n","ngram_range = (1, 3)  # Trigram setting\n","max_features = 1000  # Set max_features to 1000 for TF-IDF\n","\n","# Step 3: Train-test split before vectorization and resampling\n","X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'],\n","                                                    test_size=0.2, random_state=42,\n","                                                    stratify=df['category'])\n","\n","# Step 4: Vectorization using TF-IDF, fit on training data only\n","vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n","X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n","X_test_vec = vectorizer.transform(X_test)  # Transform test data\n","\n","#step 5: Create validation split from training data for Optuna\n","X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(\n","    X_train_vec, y_train, test_size=0.2, random_state=42, stratify=y_train\n",")\n","# smote = SMOTE(random_state=42)\n","# X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n"],"metadata":{"id":"0rxn1MbgHmiq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.category.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"o1Sx3Y3GyiiG","executionInfo":{"status":"ok","timestamp":1770274297717,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"a2f0b1a0-f4d7-4256-ef20-c0c1dd4511f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["category\n","1    15770\n","0    12644\n","2     8248\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>category</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>15770</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>12644</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8248</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["y_val_opt.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"Zcn2VyOSkhjN","executionInfo":{"status":"ok","timestamp":1770274344978,"user_tz":-330,"elapsed":29,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"dff28790-7b84-40d6-da9c-fa036b607082"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["category\n","1    2523\n","0    2023\n","2    1320\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>category</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2523</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2023</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1320</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Function to log results in MLflow\n","def log_mlflow(model_name,model, X_train, X_test, y_train, y_test,params,trial_number):\n","    with mlflow.start_run():\n","        # Log model type\n","        mlflow.set_tag(\"mlflow.runName\", f\"{trial_number}_{model_name}_TFIDF_Trigrams\")\n","        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n","\n","        # Log algorithm name as a parameter\n","        mlflow.log_param(\"algo_name\", model_name)\n","\n","        # Log hyperparameters\n","        for key, value in params.items():\n","            mlflow.log_param(key, value)\n","\n","        # Train model\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        y_pred_proba = model.predict_proba(X_test)\n","\n","        # Log accuracy\n","        accuracy = accuracy_score(y_test, y_pred)\n","        log_loss_value = log_loss(y_test, y_pred_proba)\n","\n","        mlflow.log_metric(\"accuracy\", accuracy)\n","        mlflow.log_metric(\"log_loss\", log_loss_value)\n","\n","\n","\n","        # Log classification report\n","        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n","        for label, metrics in classification_rep.items():\n","            if isinstance(metrics, dict):\n","                for metric, value in metrics.items():\n","                    mlflow.log_metric(f\"{label}_{metric}\", value)\n","\n","        # Log the model\n","        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n","\n","        return accuracy,log_loss_value"],"metadata":{"id":"cMz9Fon2Lw9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Optuna objective function for XGBoost\n","def objective_xgboost(trial):\n","    params = {\n","        \"objective\": \"multi:softprob\",\n","        \"num_class\": 3,\n","        \"eval_metric\": \"mlogloss\",\n","\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 400),\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 10),\n","\n","        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.9),\n","        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n","\n","        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n","        \"gamma\": trial.suggest_float(\"gamma\", 0, 3),\n","        \"random_state\": 42\n","    }\n","\n","    model = XGBClassifier(**params)\n","\n","    #train on training split\n","    model.fit(X_train_opt, y_train_opt,\n","              verbose=False)\n","\n","    preds = model.predict_proba(X_val_opt)\n","\n","    #return log loss\n","    return log_loss(y_val_opt, preds)\n","\n","# Step 7: Run Optuna for XGBoost, log the best model only\n","def run_optuna_experiment():\n","    #create optuna study\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective_xgboost, n_trials=20)\n","\n","    # Get the best parameters and log only the best model\n","    best_params = study.best_params\n","    print(f\"Best trial value :{study.best_value}\")\n","    print(f\" Best Parameters: {best_params}\")\n","\n","    #create best model\n","    best_model = XGBClassifier(\n","        objective=\"multi:softprob\",\n","        num_class=3,\n","        eval_metric=\"mlogloss\",\n","        random_state=42,\n","        **best_params  # Unpack best_params AFTER setting fixed params\n","    )\n","\n","    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n","    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n","    print(\"Experiment Done\")\n","\n","# Run the experiment for XGBoost\n","run_optuna_experiment()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDujKpnsy61B","executionInfo":{"status":"ok","timestamp":1770277502423,"user_tz":-330,"elapsed":474999,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"5ad5e044-0f7b-49c4-e9ee-2fee4ad6f240","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2026-02-05 06:52:36,373] A new study created in memory with name: no-name-db396dff-6094-44cf-8727-32bb0a3a2b3d\n","[I 2026-02-05 06:56:01,688] Trial 0 finished with value: 0.7245236177702362 and parameters: {'n_estimators': 367, 'learning_rate': 0.012340709295020411, 'max_depth': 10, 'subsample': 0.835831007487513, 'colsample_bytree': 0.8601028165752758, 'min_child_weight': 2, 'gamma': 2.654590570097888}. Best is trial 0 with value: 0.7245236177702362.\n","[I 2026-02-05 06:56:54,576] Trial 1 finished with value: 0.7004559045108357 and parameters: {'n_estimators': 250, 'learning_rate': 0.037415293593927604, 'max_depth': 6, 'subsample': 0.7305337476173542, 'colsample_bytree': 0.6848266593368135, 'min_child_weight': 4, 'gamma': 2.6527573910119875}. Best is trial 1 with value: 0.7004559045108357.\n","[I 2026-02-05 06:59:22,645] Trial 2 finished with value: 1.014136926321141 and parameters: {'n_estimators': 254, 'learning_rate': 0.001131162301703109, 'max_depth': 9, 'subsample': 0.7908434605819051, 'colsample_bytree': 0.7742275635567326, 'min_child_weight': 5, 'gamma': 0.6505561695149799}. Best is trial 1 with value: 0.7004559045108357.\n","[I 2026-02-05 07:00:22,156] Trial 3 finished with value: 0.6797703057089057 and parameters: {'n_estimators': 242, 'learning_rate': 0.03939641525644539, 'max_depth': 7, 'subsample': 0.7168323439237589, 'colsample_bytree': 0.7006689207589882, 'min_child_weight': 4, 'gamma': 2.6847150799613115}. Best is trial 3 with value: 0.6797703057089057.\n","[I 2026-02-05 07:02:50,522] Trial 4 finished with value: 0.8886763202380892 and parameters: {'n_estimators': 321, 'learning_rate': 0.003765149814118006, 'max_depth': 9, 'subsample': 0.8015539688160606, 'colsample_bytree': 0.8674982889073096, 'min_child_weight': 5, 'gamma': 2.8546242739500256}. Best is trial 3 with value: 0.6797703057089057.\n","[I 2026-02-05 07:05:03,455] Trial 5 finished with value: 0.7883002900781569 and parameters: {'n_estimators': 321, 'learning_rate': 0.010128295336228577, 'max_depth': 8, 'subsample': 0.7746811881290967, 'colsample_bytree': 0.6317902430371513, 'min_child_weight': 4, 'gamma': 0.7728193079037473}. Best is trial 3 with value: 0.6797703057089057.\n","[I 2026-02-05 07:06:56,680] Trial 6 finished with value: 0.6551761097827498 and parameters: {'n_estimators': 345, 'learning_rate': 0.03453316701365305, 'max_depth': 7, 'subsample': 0.8626920995642706, 'colsample_bytree': 0.8498087724701788, 'min_child_weight': 3, 'gamma': 1.91039882273295}. Best is trial 6 with value: 0.6551761097827498.\n","[I 2026-02-05 07:08:38,847] Trial 7 finished with value: 1.0100448798166326 and parameters: {'n_estimators': 316, 'learning_rate': 0.0012796253386882772, 'max_depth': 6, 'subsample': 0.7998240070507523, 'colsample_bytree': 0.6569273604238534, 'min_child_weight': 3, 'gamma': 1.693347249315309}. Best is trial 6 with value: 0.6551761097827498.\n","[I 2026-02-05 07:10:44,178] Trial 8 finished with value: 0.9615435769648679 and parameters: {'n_estimators': 299, 'learning_rate': 0.0025841744506189903, 'max_depth': 6, 'subsample': 0.7758450002232105, 'colsample_bytree': 0.7607509146062826, 'min_child_weight': 2, 'gamma': 1.049198669626156}. Best is trial 6 with value: 0.6551761097827498.\n","[I 2026-02-05 07:15:15,178] Trial 9 finished with value: 1.0028122930850876 and parameters: {'n_estimators': 307, 'learning_rate': 0.0011048287144600816, 'max_depth': 10, 'subsample': 0.8403616507746112, 'colsample_bytree': 0.6365542429144407, 'min_child_weight': 1, 'gamma': 1.400239915433522}. Best is trial 6 with value: 0.6551761097827498.\n","[I 2026-02-05 07:17:20,264] Trial 10 finished with value: 0.5794847762819042 and parameters: {'n_estimators': 376, 'learning_rate': 0.0771521823971142, 'max_depth': 7, 'subsample': 0.892825112099751, 'colsample_bytree': 0.8141706572223967, 'min_child_weight': 3, 'gamma': 0.12485935724235353}. Best is trial 10 with value: 0.5794847762819042.\n","[I 2026-02-05 07:19:11,152] Trial 11 finished with value: 0.57296955005269 and parameters: {'n_estimators': 399, 'learning_rate': 0.08668161085758007, 'max_depth': 7, 'subsample': 0.8993084599290517, 'colsample_bytree': 0.8152358652549453, 'min_child_weight': 3, 'gamma': 1.9035992783158993}. Best is trial 11 with value: 0.57296955005269.\n","[I 2026-02-05 07:21:30,049] Trial 12 finished with value: 0.5712682320209316 and parameters: {'n_estimators': 399, 'learning_rate': 0.08977057379950991, 'max_depth': 7, 'subsample': 0.8977668748156397, 'colsample_bytree': 0.8044898499511512, 'min_child_weight': 2, 'gamma': 0.001912641043349067}. Best is trial 12 with value: 0.5712682320209316.\n","[I 2026-02-05 07:23:59,799] Trial 13 finished with value: 0.5921533400078756 and parameters: {'n_estimators': 399, 'learning_rate': 0.051877329132666364, 'max_depth': 8, 'subsample': 0.8898869277666115, 'colsample_bytree': 0.8003387484637042, 'min_child_weight': 1, 'gamma': 2.0994160108057396}. Best is trial 12 with value: 0.5712682320209316.\n","[I 2026-02-05 07:25:27,454] Trial 14 finished with value: 0.6045686071514066 and parameters: {'n_estimators': 205, 'learning_rate': 0.09681449767470351, 'max_depth': 7, 'subsample': 0.8992567921205109, 'colsample_bytree': 0.8991207245290054, 'min_child_weight': 2, 'gamma': 0.07066590076006607}. Best is trial 12 with value: 0.5712682320209316.\n","[I 2026-02-05 07:27:55,486] Trial 15 finished with value: 0.6764498288283671 and parameters: {'n_estimators': 399, 'learning_rate': 0.021604605491796915, 'max_depth': 8, 'subsample': 0.8576995853722609, 'colsample_bytree': 0.7255398729791115, 'min_child_weight': 2, 'gamma': 2.305173972007297}. Best is trial 12 with value: 0.5712682320209316.\n","[I 2026-02-05 07:30:05,531] Trial 16 finished with value: 0.7032437093276529 and parameters: {'n_estimators': 359, 'learning_rate': 0.021569255248844753, 'max_depth': 7, 'subsample': 0.8717948944694206, 'colsample_bytree': 0.8181149850846764, 'min_child_weight': 3, 'gamma': 1.3956764401433628}. Best is trial 12 with value: 0.5712682320209316.\n","[I 2026-02-05 07:32:58,600] Trial 17 finished with value: 0.5763095566398355 and parameters: {'n_estimators': 384, 'learning_rate': 0.06665551928922875, 'max_depth': 8, 'subsample': 0.8252762967859761, 'colsample_bytree': 0.7794822721439629, 'min_child_weight': 1, 'gamma': 0.4664575494853054}. Best is trial 12 with value: 0.5712682320209316.\n","[I 2026-02-05 07:36:12,863] Trial 18 finished with value: 0.7002068412799514 and parameters: {'n_estimators': 347, 'learning_rate': 0.017592313970848355, 'max_depth': 9, 'subsample': 0.8751515333782458, 'colsample_bytree': 0.7329684264872691, 'min_child_weight': 2, 'gamma': 1.1156634516022277}. Best is trial 12 with value: 0.5712682320209316.\n","[I 2026-02-05 07:37:50,620] Trial 19 finished with value: 0.891381048763607 and parameters: {'n_estimators': 272, 'learning_rate': 0.0059984907428336474, 'max_depth': 6, 'subsample': 0.743546991047341, 'colsample_bytree': 0.8363938774292999, 'min_child_weight': 4, 'gamma': 1.7733364519077341}. Best is trial 12 with value: 0.5712682320209316.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial value :0.5712682320209316\n"," Best Parameters: {'n_estimators': 399, 'learning_rate': 0.08977057379950991, 'max_depth': 7, 'subsample': 0.8977668748156397, 'colsample_bytree': 0.8044898499511512, 'min_child_weight': 2, 'gamma': 0.001912641043349067}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:urllib3.connectionpool:Retrying (Retry(total=6, connect=6, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ba0404bd5e0>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/runs/log-metric\n","WARNING:urllib3.connectionpool:Retrying (Retry(total=5, connect=5, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ba021abc350>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/runs/log-metric\n","WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=4, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ba021abca40>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/runs/log-metric\n","WARNING:urllib3.connectionpool:Retrying (Retry(total=3, connect=3, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ba021abce90>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/runs/log-metric\n","WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=2, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ba021abd1c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/runs/log-metric\n","WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=1, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ba021abe840>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/runs/log-metric\n","WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=0, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ba021abef60>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/runs/log-metric\n","2026/02/05 07:44:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n","/usr/local/lib/python3.12/dist-packages/mlflow/models/model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n","  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["ğŸƒ View run XGBoost_TFIDF_Trigrams at: http://ec2-98-91-228-79.compute-1.amazonaws.com:5000/#/experiments/5/runs/eec3fb0095994fbc9dc3c844e69b8273\n","ğŸ§ª View experiment at: http://ec2-98-91-228-79.compute-1.amazonaws.com:5000/#/experiments/5\n","Experiment Done\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import log_loss\n","\n","def objective_xgboost(trial):\n","    params = {\n","        \"objective\": \"multi:softprob\",\n","        \"num_class\": 3,\n","        \"eval_metric\": \"mlogloss\",\n","\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 400),\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 10),\n","        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.9),\n","        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n","        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n","        \"gamma\": trial.suggest_float(\"gamma\", 0, 3),\n","        \"tree_method\": \"hist\",   # CPU-safe\n","        \"seed\": 42\n","    }\n","\n","    #create DMatrix for training and validation\n","    dtrain = xgb.DMatrix(X_train_opt, label=y_train_opt)\n","    dval = xgb.DMatrix(X_val_opt, label=y_val_opt)\n","\n","    #Train the model\n","    booster = xgb.train(\n","        params=params,\n","        dtrain=dtrain,\n","        evals=[(dval,'validation')]\n","        verbose_eval=False\n","    )\n","\n","    #predict on validation\n","    preds = booster.predict(dval)\n","    return log_loss(y_val_opt, preds)"],"metadata":{"id":"nYWJtGF3xrQu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run Optuna and logbest model\n","\n","def run_optuna_experiment():\n","    #create optuna study\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective_xgboost, n_trials=30)\n","\n","    best_params=study.best_params\n","    print(f\"Best trial value :{study.best_value}\")\n","    print(f\" Best Parameters: {best_params}\")\n","\n","    #Final params\n","    final_params={\n","        \"objective\": \"multi:softprob\",\n","        \"num_class\": 3,\n","        \"eval_metric\": \"mlogloss\",\n","        \"tree_method\": \"hist\",\n","        \"seed\": 42,\n","        **best_params\n","    }\n","\n","    #Train on full training\n","    dtrain = xgb.DMatrix(X_train_vec, label=y_train)\n","    dval = xgb.DMatrix(X_test_vec, label=y_test)\n","\n","    #"],"metadata":{"id":"-J5MtDubx0sO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# lightgbm experiment"],"metadata":{"id":"Gh4Xj-zVHoyu"}},{"cell_type":"code","source":["mlflow.set_experiment(\"LightGBM HP Tuning\")"],"metadata":{"id":"ByIBOHJUV7ND","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770277674937,"user_tz":-330,"elapsed":331,"user":{"displayName":"Ajay Suyal","userId":"03347117319358114618"}},"outputId":"add329c4-e69c-4a09-e3f9-4d72607d5a22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2026/02/05 07:47:54 INFO mlflow.tracking.fluent: Experiment with name 'LightGBM HP Tuning' does not exist. Creating a new experiment.\n"]},{"output_type":"execute_result","data":{"text/plain":["<Experiment: artifact_location='s3://mlflow-redit-user/6', creation_time=1770277674679, experiment_id='6', last_update_time=1770277674679, lifecycle_stage='active', name='LightGBM HP Tuning', tags={}>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["from lightgbm import LGBMClassifier\n","import matplotlib.pyplot as plt"],"metadata":{"id":"oah-YcnDSOOb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Optuna objective function for LightGBM\n","def objective_lightgbm(trial):\n","    # Hyperparameter space to explore\n","    max_depth = trial.suggest_int('max_depth', 3, 8)\n","    num_leaves = trial.suggest_int('num_leaves', 2**(max_depth-1), 2**max_depth-1)\n","    reg_alpha = trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True)  # L1 regularization\n","    reg_lambda = trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True)  # L2 regularization\n","    # Log trial parameters\n","    params = {\n","        \"objective\": \"multiclass\",\n","        \"num_class\": 3,\n","        \"metric\": \"multi_logloss\",\n","\n","        'n_estimators': trial.suggest_int('n_estimators', 150,500),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n","        'max_depth': max_depth,\n","        'num_leaves': num_leaves,\n","\n","        'min_child_samples': trial.suggest_int('min_child_samples', 10,100),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),\n","\n","        'reg_alpha': reg_alpha,\n","        'reg_lambda': reg_lambda,\n","\n","        'device': 'cpu', # Changed from 'gpu' to 'cpu'\n","        'random_state': 42\n","    }\n","\n","    # Create LightGBM model\n","    model = LGBMClassifier(**params)\n","\n","    # Log each trial as a separate run in MLflow\n","    model.fit(\n","        X_train_vec, y_train,\n","        eval_set=[(X_test_vec, y_test)]\n","    )\n","\n","    probs = model.predict_proba(X_test_vec)\n","    return log_loss(y_test, probs)\n","\n","# Step 7: Run Optuna for LightGBM, log the best model, and plot the importance of each parameter\n","def run_optuna_experiment():\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective_lightgbm, n_trials=50)  # Increased to 50 trials\n","\n","    # Get the best parameters\n","    best_params = study.best_params\n","    best_model = LGBMClassifier(\n","        **best_params,\n","        objective=\"multiclass\",\n","        num_class=3,\n","        metric=\"multi_logloss\",\n","        device=\"cpu\",\n","        random_state=42\n","    )\n","\n","    # Log the best model with MLflow and print the classification report\n","    # Removed extra parameters from log_mlflow as it expects only 6 arguments\n","    log_mlflow(\"LightGBM\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n","\n","    # Plot parameter importance\n","    optuna.visualization.plot_param_importances(study).show()\n","\n","    # Plot optimization history\n","    optuna.visualization.plot_optimization_history(study).show()\n","\n","\n","# Run the experiment for LightGBM\n","run_optuna_experiment()"],"metadata":{"id":"JN2dnAl4SoS-","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1yzQHnDMwSTWiFBUkpX8dkCVSZDDn882M"},"collapsed":true,"outputId":"207a48f8-f52f-4587-8294-6c26cec3cf20"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}